{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# AutoML для временных рядов с FEDOT Industrial\n",
    "\n",
    "В этом ноутбуке мы тестируем российскую AutoML библиотеку **FEDOT Industrial** для прогнозирования финансовых временных рядов с использованием walk-forward валидации.\n",
    "\n",
    "## Особенности FEDOT Industrial:\n",
    "- **AutoML подход**: автоматический выбор архитектуры модели\n",
    "- **Композитные модели**: может строить сложные пайплайны из нескольких алгоритмов\n",
    "- **Специализация на временных рядах**: оптимизированные алгоритмы для TS\n",
    "- **Эволюционная оптимизация**: автоматический поиск лучших гиперпараметров\n",
    "- **Российская разработка**: NCCR, ITMO University\n",
    "\n",
    "## Преимущества AutoML:\n",
    "- Не требует экспертных знаний в ML\n",
    "- Автоматически находит лучшую архитектуру\n",
    "- Оптимизирует гиперпараметры\n",
    "- Строит комплексные пайплайны\n",
    "\n",
    "## Методология:\n",
    "- **Walk-forward валидация**: модель переобучается после каждого прогноза\n",
    "- **Разбивка данных**: 95% обучение, 5% тест\n",
    "- **Горизонт прогноза**: 1 шаг вперед\n",
    "- **AutoML**: FEDOT сам выберет лучшую модель\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import virtualenv\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "notebook_name = \"fedot\"\n",
    "virtualenv.cli_run([\"venvs/\" + notebook_name, \"--no-download\"])\n",
    "\n",
    "venv_dir = \"venvs/\" + notebook_name\n",
    "python_path = os.path.join(venv_dir, \"bin\", \"python\")\n",
    "display_name = \"Python (\" + notebook_name + \")\"\n",
    "kernel_name = notebook_name\n",
    "\n",
    "subprocess.check_call([os.path.join(venv_dir, \"bin\", \"pip\"), \"install\", \"ipykernel\"])\n",
    "\n",
    "subprocess.check_call([\n",
    "    python_path, \"-m\", \"ipykernel\", \"install\",\n",
    "    \"--user\",\n",
    "    \"--name\", kernel_name,\n",
    "    \"--display-name\", display_name\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/predictors/univariate/venvs/fedot/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "\n",
    "pip_path = os.path.join(sys.prefix, \"bin\", \"pip\")\n",
    "\n",
    "subprocess.check_call([pip_path, \"install\", \"fedot[extra]\", \"opencv-python-headless\", \"matplotlib\", \"scikit-learn\", \"pandas\", \"numpy\", \"seaborn\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEDOT загружен успешно!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# FEDOT\n",
    "from fedot import Fedot\n",
    "from fedot.core.data.data import InputData\n",
    "from fedot.core.data.data_split import train_test_data_setup\n",
    "from fedot.core.repository.dataset_types import DataTypesEnum\n",
    "from fedot.core.repository.tasks import Task, TaskTypesEnum, TsForecastingParams\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "print(\"FEDOT загружен успешно!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directional_accuracy(actual: np.ndarray, predicted: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Доля совпавших направлений изменения: рост/падение.\n",
    "    \"\"\"\n",
    "    actual_dir = np.sign(np.diff(actual))\n",
    "    pred_dir   = np.sign(np.diff(predicted))\n",
    "    \n",
    "    return (actual_dir == pred_dir).mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено 10 временных рядов:\n",
      "  AFLT: 2375 точек данных\n",
      "  LKOH: 2375 точек данных\n",
      "  MOEX: 2375 точек данных\n",
      "  NVTK: 2373 точек данных\n",
      "  PIKK: 2375 точек данных\n",
      "  SBER: 2375 точек данных\n",
      "  VKCO: 1197 точек данных\n",
      "  VTBR: 1722 точек данных\n",
      "  X5: 1499 точек данных\n",
      "  YDEX: 2339 точек данных\n"
     ]
    }
   ],
   "source": [
    "def load_series_map(series_dir=\"../../data/series\"):\n",
    "    \"\"\"Загружает временные ряды из CSV файлов\"\"\"\n",
    "    series_map = {}\n",
    "    series_path = Path(series_dir)\n",
    "\n",
    "    if not series_path.exists():\n",
    "        raise FileNotFoundError(f\"Папка не найдена: {series_dir}\")\n",
    "    \n",
    "    for csv_file in series_path.glob(\"*.csv\"):\n",
    "        ticker = csv_file.stem.upper()\n",
    "        df = pd.read_csv(csv_file)\n",
    "        if \"timestamp\" not in df.columns or \"close\" not in df.columns:\n",
    "            raise ValueError(f\"{csv_file.name} не содержит 'timestamp' или 'close'\")\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True)\n",
    "        df = df[[\"timestamp\", \"close\"]].sort_values(\"timestamp\").reset_index(drop=True)\n",
    "        series_map[ticker] = df\n",
    "    \n",
    "    return series_map\n",
    "\n",
    "series_map = load_series_map(\"../../data/series\")\n",
    "print(f\"Загружено {len(series_map)} временных рядов:\")\n",
    "for ticker, df in series_map.items():\n",
    "    print(f\"  {ticker}: {len(df)} точек данных\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFLT: train=2256, test=119\n",
      "LKOH: train=2256, test=119\n",
      "MOEX: train=2256, test=119\n",
      "NVTK: train=2254, test=119\n",
      "PIKK: train=2256, test=119\n",
      "SBER: train=2256, test=119\n",
      "VKCO: train=1137, test=60\n",
      "VTBR: train=1635, test=87\n",
      "X5: train=1424, test=75\n",
      "YDEX: train=2222, test=117\n",
      "\n",
      "Данные подготовлены для 10 тикеров\n"
     ]
    }
   ],
   "source": [
    "def prepare_fedot_data(series_map, test_ratio=0.05):\n",
    "    \"\"\"\n",
    "    Подготавливает данные для FEDOT с разбивкой 95%/5%\n",
    "    \n",
    "    Args:\n",
    "        series_map: словарь с временными рядами\n",
    "        test_ratio: доля тестовых данных (0.05 = 5%)\n",
    "    \n",
    "    Returns:\n",
    "        prepared_data: словарь с подготовленными данными для каждого тикера\n",
    "    \"\"\"\n",
    "    prepared_data = {}\n",
    "    \n",
    "    for ticker, df in series_map.items():\n",
    "        values = df['close'].values\n",
    "        timestamps = df['timestamp'].values\n",
    "        \n",
    "        split_idx = int(len(values) * (1 - test_ratio))\n",
    "        train_data = values[:split_idx]\n",
    "        test_data = values[split_idx:]\n",
    "        train_timestamps = timestamps[:split_idx]\n",
    "        test_timestamps = timestamps[split_idx:]\n",
    "        \n",
    "        prepared_data[ticker] = {\n",
    "            'full_data': values,\n",
    "            'train_data': train_data,\n",
    "            'test_data': test_data,\n",
    "            'train_timestamps': train_timestamps,\n",
    "            'test_timestamps': test_timestamps,\n",
    "            'split_idx': split_idx\n",
    "        }\n",
    "        \n",
    "        print(f\"{ticker}: train={len(train_data)}, test={len(test_data)}\")\n",
    "    \n",
    "    return prepared_data\n",
    "\n",
    "def create_fedot_input_data(data, forecast_length=1):\n",
    "    \"\"\"\n",
    "    Создает InputData для FEDOT из временного ряда\n",
    "    \n",
    "    Args:\n",
    "        data: массив значений временного ряда\n",
    "        forecast_length: горизонт прогноза\n",
    "    \n",
    "    Returns:\n",
    "        InputData: объект данных для FEDOT\n",
    "    \"\"\"\n",
    "    task = Task(\n",
    "        TaskTypesEnum.ts_forecasting,\n",
    "        TsForecastingParams(forecast_length=forecast_length)\n",
    "    )\n",
    "    \n",
    "    # Создаем InputData\n",
    "    return InputData.from_numpy_time_series(\n",
    "        features_array=ts_values,\n",
    "        target_array=ts_values,\n",
    "        idx=ts_timestamps,\n",
    "        task=task,\n",
    "        data_type=DataTypesEnum.ts\n",
    "    )\n",
    "\n",
    "prepared_data = prepare_fedot_data(series_map, test_ratio=0.05)\n",
    "print(f\"\\nДанные подготовлены для {len(prepared_data)} тикеров\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fedot_input_data(values: np.ndarray,\n",
    "                            timestamps: np.ndarray,\n",
    "                            forecast_length: int = 1) -> InputData:\n",
    "    \"\"\"Фабрика InputData для временных рядов.\"\"\"\n",
    "    task = Task(\n",
    "        TaskTypesEnum.ts_forecasting,\n",
    "        TsForecastingParams(forecast_length=forecast_length)\n",
    "    )\n",
    "    return InputData.from_numpy_time_series(\n",
    "        features_array=values,\n",
    "        target_array=values,\n",
    "        idx=timestamps,\n",
    "        task=task,\n",
    "        data_type=DataTypesEnum.ts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward_fedot(ticker: str,\n",
    "                       ticker_data: dict,\n",
    "                       timeout_minutes: float = 5.0):\n",
    "    \"\"\"\n",
    "    Однократное обучение FEDOT + walk-forward прогнозы.\n",
    "    Время = train_time + avg(prediction_time).\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {ticker}: FEDOT AutoML fast Walk-forward ===\")\n",
    "\n",
    "    train_vals = ticker_data['train_data']\n",
    "    test_vals  = ticker_data['test_data']\n",
    "    train_idx  = ticker_data['train_timestamps']\n",
    "    test_idx   = ticker_data['test_timestamps']\n",
    "    split_idx  = ticker_data['split_idx']\n",
    "\n",
    "    input_train = create_fedot_input_data(\n",
    "        values=train_vals,\n",
    "        timestamps=train_idx,\n",
    "        forecast_length=1\n",
    "    )\n",
    "    auto_model = Fedot(\n",
    "        problem='ts_forecasting',\n",
    "        timeout=timeout_minutes,\n",
    "        preset='ts',\n",
    "        n_jobs=1,\n",
    "        safe_mode=True,\n",
    "        cv_folds=3,\n",
    "        early_stopping_iterations=10,\n",
    "        with_tuning=False\n",
    "    )\n",
    "    t0 = time.time()\n",
    "    auto_model.fit(features=input_train, target=train_vals)\n",
    "    train_time = time.time() - t0\n",
    "    print(f\"  Trained in {train_time:.2f}s → pipeline: {auto_model.current_pipeline}\")\n",
    "\n",
    "    preds = []\n",
    "    times = []\n",
    "    full_vals = np.concatenate([train_vals, test_vals])\n",
    "    full_idx  = np.concatenate([train_idx, test_idx])\n",
    "    n_steps   = len(test_vals)\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        end = split_idx + i\n",
    "        hist_vals = full_vals[:end]\n",
    "        hist_idx  = full_idx[:end]\n",
    "\n",
    "        if len(hist_vals) < 10:\n",
    "            continue\n",
    "\n",
    "        input_loop = create_fedot_input_data(\n",
    "            values=hist_vals,\n",
    "            timestamps=hist_idx,\n",
    "            forecast_length=1\n",
    "        )\n",
    "        train_data, forecast_data = train_test_data_setup(input_loop)\n",
    "\n",
    "        t1 = time.time()\n",
    "        raw_forecast = auto_model.forecast(forecast_data)\n",
    "        dt = time.time() - t1\n",
    "\n",
    "        if hasattr(raw_forecast, 'predict'):\n",
    "            pred = raw_forecast.predict[0]\n",
    "        elif isinstance(raw_forecast, np.ndarray):\n",
    "            pred = raw_forecast[0]\n",
    "        elif isinstance(raw_forecast, list):\n",
    "            pred = raw_forecast[0]\n",
    "        else:\n",
    "            pred = float(raw_forecast)\n",
    "\n",
    "        preds.append(pred)\n",
    "        times.append(dt)\n",
    "\n",
    "    preds = np.array(preds)\n",
    "    actuals = test_vals[:len(preds)]\n",
    "\n",
    "    mae_v   = mean_absolute_error(actuals, preds)\n",
    "    rmse_v  = mean_squared_error(actuals, preds, squared=False)\n",
    "    mape_v  = mean_absolute_percentage_error(actuals, preds) * 100\n",
    "    da_v    = directional_accuracy(actuals, preds)\n",
    "\n",
    "    avg_pred_time = np.mean(times)\n",
    "    eff_time_step = train_time + avg_pred_time\n",
    "\n",
    "    print(f\"\\nResults for {ticker}:\")\n",
    "    print(f\"  MAE:      {mae_v:.4f}\")\n",
    "    print(f\"  MAPE:     {mape_v:.2f}%\")\n",
    "    print(f\"  RMSE:     {rmse_v:.4f}\")\n",
    "    print(f\"  DA:       {da_v:.2f}%\")\n",
    "    print(f\"  Train:    {train_time:.2f}s\")\n",
    "    print(f\"  Avg pred: {avg_pred_time:.4f}s\")\n",
    "    print(f\"  Eff/step: {eff_time_step:.4f}s\")\n",
    "\n",
    "    return {\n",
    "        'actuals': test_vals,\n",
    "        'predictions': preds,\n",
    "        'times':       times,\n",
    "        'metrics': {\n",
    "            'MAE':               mae_v,\n",
    "            'MAPE (%)':          mape_v,\n",
    "            'RMSE':              rmse_v,\n",
    "            'DA (%)':            da_v,\n",
    "            'Train Time (s)':    train_time,\n",
    "            'Avg Pred Time (s)': avg_pred_time,\n",
    "            'Eff Time/step (s)': eff_time_step\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестируем FEDOT AutoML на тикерах: ['AFLT', 'LKOH', 'MOEX', 'NVTK', 'PIKK', 'SBER', 'VKCO', 'VTBR', 'X5', 'YDEX']\n",
      "Это может занять некоторое время, так как FEDOT ищет оптимальную архитектуру...\n",
      "\n",
      "================================================================================\n",
      "ОБРАБОТКА ТИКЕРА: AFLT\n",
      "================================================================================\n",
      "\n",
      "--- Конфигурация: FEDOT_Fast (Быстрый поиск модели (1 мин)) ---\n",
      "\n",
      "=== AFLT: FEDOT AutoML fast Walk-forward ===\n",
      "2025-06-17 18:26:16,302 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 111\n",
      "2025-06-17 18:26:16,456 - ApiComposer - Initial pipeline was fitted in 0.2 sec.\n",
      "2025-06-17 18:26:16,459 - ApiComposer - Taking into account n_folds=3, estimated fit time for initial assumption is 0.5 sec.\n",
      "2025-06-17 18:26:16,476 - ApiComposer - AutoML configured. Parameters tuning: False. Time limit: 1 min. Set of candidate models: ['adareg', 'ar', 'diff_filter', 'dtreg', 'ets', 'fast_ica', 'gaussian_filter', 'glm', 'lagged', 'lasso', 'linear', 'locf', 'normalization', 'pca', 'polyfit', 'ridge', 'scaling', 'sgdr', 'smoothing', 'sparse_lagged', 'topological_features', 'ts_naive_average'].\n",
      "2025-06-17 18:26:16,907 - ApiComposer - Pipeline composition started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 0/10000 [00:00<?, ?gen/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:26:18,434 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 292\n",
      "2025-06-17 18:26:20,846 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 292\n",
      "2025-06-17 18:26:22,134 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 292\n",
      "2025-06-17 18:26:34,103 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 292\n",
      "2025-06-17 18:26:35,318 - MultiprocessingDispatcher - 4 individuals out of 4 in previous population were evaluated successfully.\n",
      "2025-06-17 18:26:47,337 - SparseLaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 292\n",
      "2025-06-17 18:26:51,213 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 292\n",
      "2025-06-17 18:28:09,302 - MultiprocessingDispatcher - 11 individuals out of 21 in previous population were evaluated successfully.\n",
      "2025-06-17 18:28:09,330 - GroupedCondition - Optimisation stopped: Time limit is reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 0/10000 [01:52<?, ?gen/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:28:09,521 - ApiComposer - Model generation finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:28:09,644 - FEDOT logger - Final pipeline was fitted\n",
      "2025-06-17 18:28:09,646 - FEDOT logger - Final pipeline: {'depth': 2, 'length': 2, 'nodes': [ar, smoothing]}\n",
      "ar - {'lag_1': 7, 'lag_2': 12}\n",
      "smoothing - {}\n",
      "  Trained in 113.56s → pipeline: {'depth': 2, 'length': 2, 'nodes': [ar, smoothing]}\n",
      "\n",
      "Results for AFLT:\n",
      "  MAE:      4.8424\n",
      "  MAPE:     7.73%\n",
      "  RMSE:     5.9361\n",
      "  DA:       48.31%\n",
      "  Train:    113.56s\n",
      "  Avg pred: 0.0110s\n",
      "  Eff/step: 113.5715s\n",
      "\n",
      "--- Конфигурация: FEDOT_Balanced (Сбалансированный поиск (5 мин)) ---\n",
      "\n",
      "=== AFLT: FEDOT AutoML fast Walk-forward ===\n",
      "2025-06-17 18:28:11,291 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 111\n",
      "2025-06-17 18:28:11,395 - ApiComposer - Initial pipeline was fitted in 0.1 sec.\n",
      "2025-06-17 18:28:11,400 - ApiComposer - Taking into account n_folds=3, estimated fit time for initial assumption is 0.4 sec.\n",
      "2025-06-17 18:28:11,423 - ApiComposer - AutoML configured. Parameters tuning: False. Time limit: 5 min. Set of candidate models: ['adareg', 'ar', 'diff_filter', 'dtreg', 'ets', 'fast_ica', 'gaussian_filter', 'glm', 'lagged', 'lasso', 'linear', 'locf', 'normalization', 'pca', 'polyfit', 'ridge', 'scaling', 'sgdr', 'smoothing', 'sparse_lagged', 'topological_features', 'ts_naive_average'].\n",
      "2025-06-17 18:28:11,879 - ApiComposer - Pipeline composition started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 0/10000 [00:00<?, ?gen/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:28:13,415 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 292\n",
      "2025-06-17 18:28:15,733 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 292\n",
      "2025-06-17 18:28:17,362 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 292\n",
      "2025-06-17 18:28:31,910 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 292\n",
      "2025-06-17 18:28:33,066 - MultiprocessingDispatcher - 4 individuals out of 4 in previous population were evaluated successfully.\n",
      "2025-06-17 18:28:53,701 - SparseLaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 292\n",
      "2025-06-17 18:29:14,901 - SparseLaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 292\n",
      "2025-06-17 18:30:32,576 - MultiprocessingDispatcher - 21 individuals out of 21 in previous population were evaluated successfully.\n",
      "2025-06-17 18:38:59,863 - MultiprocessingDispatcher - 6 individuals out of 8 in previous population were evaluated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 1/10000 [11:58<1995:35:51, 718.49s/gen]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:40:10,397 - GroupedCondition - Optimisation stopped: Time limit is reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 1/10000 [11:58<1995:40:25, 718.51s/gen]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:40:10,585 - ApiComposer - Model generation finished\n",
      "2025-06-17 18:40:10,642 - FEDOT logger - Final pipeline was fitted\n",
      "2025-06-17 18:40:10,643 - FEDOT logger - Final pipeline: {'depth': 1, 'length': 1, 'nodes': [ar]}\n",
      "ar - {'lag_1': 7, 'lag_2': 12}\n",
      "  Trained in 719.48s → pipeline: {'depth': 1, 'length': 1, 'nodes': [ar]}\n",
      "\n",
      "Results for AFLT:\n",
      "  MAE:      3.8599\n",
      "  MAPE:     6.08%\n",
      "  RMSE:     4.8537\n",
      "  DA:       48.31%\n",
      "  Train:    719.48s\n",
      "  Avg pred: 0.0050s\n",
      "  Eff/step: 719.4813s\n",
      "\n",
      "================================================================================\n",
      "ОБРАБОТКА ТИКЕРА: LKOH\n",
      "================================================================================\n",
      "\n",
      "--- Конфигурация: FEDOT_Fast (Быстрый поиск модели (1 мин)) ---\n",
      "\n",
      "=== LKOH: FEDOT AutoML fast Walk-forward ===\n",
      "2025-06-17 18:40:11,660 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 556\n",
      "2025-06-17 18:40:11,877 - ApiComposer - Initial pipeline was fitted in 0.2 sec.\n",
      "2025-06-17 18:40:11,880 - ApiComposer - Taking into account n_folds=3, estimated fit time for initial assumption is 0.7 sec.\n",
      "2025-06-17 18:40:11,895 - ApiComposer - AutoML configured. Parameters tuning: False. Time limit: 1 min. Set of candidate models: ['adareg', 'ar', 'diff_filter', 'dtreg', 'ets', 'fast_ica', 'gaussian_filter', 'glm', 'lagged', 'lasso', 'linear', 'locf', 'normalization', 'pca', 'polyfit', 'ridge', 'scaling', 'sgdr', 'smoothing', 'sparse_lagged', 'topological_features', 'ts_naive_average'].\n",
      "2025-06-17 18:40:12,396 - ApiComposer - Pipeline composition started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 0/10000 [00:00<?, ?gen/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:40:13,891 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 216\n",
      "2025-06-17 18:40:16,128 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 216\n",
      "2025-06-17 18:40:16,838 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 216\n",
      "2025-06-17 18:40:23,610 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 216\n",
      "2025-06-17 18:40:24,854 - MultiprocessingDispatcher - 4 individuals out of 4 in previous population were evaluated successfully.\n",
      "2025-06-17 18:42:15,700 - GroupedCondition - Optimisation stopped: Time limit is reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 0/10000 [02:03<?, ?gen/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:42:15,932 - ApiComposer - Model generation finished\n",
      "2025-06-17 18:42:16,042 - FEDOT logger - Final pipeline was fitted\n",
      "2025-06-17 18:42:16,044 - FEDOT logger - Final pipeline: {'depth': 2, 'length': 2, 'nodes': [ar, smoothing]}\n",
      "ar - {'lag_1': 7, 'lag_2': 12}\n",
      "smoothing - {}\n",
      "  Trained in 124.51s → pipeline: {'depth': 2, 'length': 2, 'nodes': [ar, smoothing]}\n",
      "\n",
      "Results for LKOH:\n",
      "  MAE:      262.7068\n",
      "  MAPE:     3.76%\n",
      "  RMSE:     336.4433\n",
      "  DA:       48.31%\n",
      "  Train:    124.51s\n",
      "  Avg pred: 0.0143s\n",
      "  Eff/step: 124.5242s\n",
      "\n",
      "--- Конфигурация: FEDOT_Balanced (Сбалансированный поиск (5 мин)) ---\n",
      "\n",
      "=== LKOH: FEDOT AutoML fast Walk-forward ===\n",
      "2025-06-17 18:42:18,074 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 556\n",
      "2025-06-17 18:42:18,287 - ApiComposer - Initial pipeline was fitted in 0.2 sec.\n",
      "2025-06-17 18:42:18,289 - ApiComposer - Taking into account n_folds=3, estimated fit time for initial assumption is 0.7 sec.\n",
      "2025-06-17 18:42:18,306 - ApiComposer - AutoML configured. Parameters tuning: False. Time limit: 5 min. Set of candidate models: ['adareg', 'ar', 'diff_filter', 'dtreg', 'ets', 'fast_ica', 'gaussian_filter', 'glm', 'lagged', 'lasso', 'linear', 'locf', 'normalization', 'pca', 'polyfit', 'ridge', 'scaling', 'sgdr', 'smoothing', 'sparse_lagged', 'topological_features', 'ts_naive_average'].\n",
      "2025-06-17 18:42:18,825 - ApiComposer - Pipeline composition started.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generations:   0%|          | 0/10000 [00:00<?, ?gen/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:42:20,668 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 216\n",
      "2025-06-17 18:42:23,375 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 216\n",
      "2025-06-17 18:42:24,226 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 216\n",
      "2025-06-17 18:42:31,741 - LaggedTransformationImplementation - Window size of lagged transformation was changed by WindowSizeSelector from 0 to 216\n",
      "2025-06-17 18:42:33,185 - MultiprocessingDispatcher - 4 individuals out of 4 in previous population were evaluated successfully.\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "\n",
    "test_tickers = list(prepared_data.keys())\n",
    "print(f\"Тестируем FEDOT AutoML на тикерах: {test_tickers}\")\n",
    "print(f\"Это может занять некоторое время, так как FEDOT ищет оптимальную архитектуру...\")\n",
    "\n",
    "fedot_configs = {\n",
    "    'FEDOT_Fast': {\n",
    "        'timeout_minutes': 1,  # Быстрый режим\n",
    "        'description': 'Быстрый поиск модели (1 мин)'\n",
    "    },\n",
    "    'FEDOT_Balanced': {\n",
    "        'timeout_minutes': 5,  # Сбалансированный режим  \n",
    "        'description': 'Сбалансированный поиск (5 мин)'\n",
    "    }\n",
    "}\n",
    "\n",
    "for ticker in test_tickers:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ОБРАБОТКА ТИКЕРА: {ticker}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    ticker_data = prepared_data[ticker]\n",
    "    ticker_results = {}\n",
    "    \n",
    "    for config_name, config in fedot_configs.items():\n",
    "        try:\n",
    "            print(f\"\\n--- Конфигурация: {config_name} ({config['description']}) ---\")\n",
    "            \n",
    "            result = walk_forward_fedot(\n",
    "                ticker=ticker,\n",
    "                ticker_data=ticker_data,\n",
    "                timeout_minutes=config['timeout_minutes']\n",
    "            )\n",
    "            \n",
    "            ticker_results[config_name] = result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n!!! ОШИБКА с конфигурацией {config_name} для {ticker}: {e}\")\n",
    "            ticker_results[config_name] = {\n",
    "                'metrics': {\n",
    "                    'MAE': np.nan,\n",
    "                    'MAPE (%)': np.nan,\n",
    "                    'RMSE': np.nan,\n",
    "                    'DA (%)': np.nan,\n",
    "                    'Avg Time (s)': np.nan\n",
    "                },\n",
    "                'model_analysis': {}\n",
    "            }\n",
    "\n",
    "            \n",
    "    \n",
    "    all_results[ticker] = ticker_results\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"FEDOT AUTOML ОБРАБОТКА ЗАВЕРШЕНА\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = []\n",
    "model_analysis_data = []\n",
    "\n",
    "for ticker, ticker_results in all_results.items():\n",
    "    for config_name, result in ticker_results.items():\n",
    "        metrics = result['metrics']\n",
    "        summary_data.append({\n",
    "            'Ticker': ticker,\n",
    "            'Config': config_name,\n",
    "            'MAE': metrics['MAE'],\n",
    "            'MAPE (%)': metrics['MAPE (%)'],\n",
    "            'RMSE': metrics['RMSE'],\n",
    "            'DA (%)': metrics['DA (%)'],\n",
    "            'Avg Time (s)': metrics['Eff Time/step (s)']\n",
    "        })\n",
    "        \n",
    "        if 'model_analysis' in result:\n",
    "            for model_name, count in result['model_analysis'].items():\n",
    "                model_analysis_data.append({\n",
    "                    'Ticker': ticker,\n",
    "                    'Config': config_name,\n",
    "                    'Model': model_name,\n",
    "                    'Usage_Count': count\n",
    "                })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "model_df = pd.DataFrame(model_analysis_data)\n",
    "\n",
    "if len(summary_df) > 0:\n",
    "    config_summary = summary_df.groupby('Config').agg({\n",
    "        'MAE': 'mean',\n",
    "        'MAPE (%)': 'mean',\n",
    "        'RMSE': 'mean',\n",
    "        'DA (%)': 'mean',\n",
    "        'Avg Time (s)': 'mean'\n",
    "    }).round(4)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ИТОГОВАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ FEDOT AUTOML\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nДетальные результаты по тикерам и конфигурациям:\")\n",
    "    display(summary_df.round(4))\n",
    "    \n",
    "    print(\"\\nСредние показатели по конфигурациям:\")\n",
    "    display(config_summary)\n",
    "    \n",
    "    if len(model_df) > 0:\n",
    "        print(\"\\nАнализ автоматически найденных моделей:\")\n",
    "        model_summary = model_df.groupby(['Config', 'Model']).agg({\n",
    "            'Usage_Count': 'sum'\n",
    "        }).reset_index().sort_values('Usage_Count', ascending=False)\n",
    "        display(model_summary.head(10))\n",
    "\n",
    "    if len(summary_df) > 1:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('FEDOT AutoML - Walk-forward валидация', fontsize=16)\n",
    "        \n",
    "        summary_df_clean = summary_df.dropna()\n",
    "        \n",
    "        if len(summary_df_clean) > 0:\n",
    "            pivot_mape = summary_df_clean.pivot(index='Ticker', columns='Config', values='MAPE (%)')\n",
    "            if not pivot_mape.empty:\n",
    "                pivot_mape.plot(kind='bar', ax=axes[0,0])\n",
    "                axes[0,0].set_title('MAPE (%)')\n",
    "                axes[0,0].set_ylabel('MAPE (%)')\n",
    "                axes[0,0].legend()\n",
    "            \n",
    "            pivot_rmse = summary_df_clean.pivot(index='Ticker', columns='Config', values='RMSE')\n",
    "            if not pivot_rmse.empty:\n",
    "                pivot_rmse.plot(kind='bar', ax=axes[0,1])\n",
    "                axes[0,1].set_title('RMSE')\n",
    "                axes[0,1].set_ylabel('RMSE')\n",
    "                axes[0,1].legend()\n",
    "            \n",
    "            pivot_da = summary_df_clean.pivot(index='Ticker', columns='Config', values='DA (%)')\n",
    "            if not pivot_da.empty:\n",
    "                pivot_da.plot(kind='bar', ax=axes[1,0])\n",
    "                axes[1,0].set_title('Directional Accuracy (%)')\n",
    "                axes[1,0].set_ylabel('DA (%)')\n",
    "                axes[1,0].legend()\n",
    "            \n",
    "            pivot_time = summary_df_clean.pivot(index='Ticker', columns='Config', values='Avg Time (s)')\n",
    "            if not pivot_time.empty:\n",
    "                pivot_time.plot(kind='bar', ax=axes[1,1])\n",
    "                axes[1,1].set_title('Среднее время поиска и прогноза (сек)')\n",
    "                axes[1,1].set_ylabel('Время (с)')\n",
    "                axes[1,1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        if len(model_df) > 0:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            model_counts = model_df.groupby('Model')['Usage_Count'].sum().sort_values(ascending=False)\n",
    "            \n",
    "            if len(model_counts) > 0:\n",
    "                model_counts.head(10).plot(kind='bar')\n",
    "                plt.title('Топ-10 моделей, найденных FEDOT AutoML')\n",
    "                plt.xlabel('Модель')\n",
    "                plt.ylabel('Количество использований')\n",
    "                plt.xticks(rotation=45, ha='right')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "else:\n",
    "    print(\"Нет данных для отображения\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fedot_forecasts(ticker, ticker_results, ticker_data):\n",
    "    \"\"\"Построение графиков прогнозов FEDOT для одного тикера\"\"\"\n",
    "    \n",
    "    best_config = None\n",
    "    best_mape = float('inf')\n",
    "    \n",
    "    for config_name, result in ticker_results.items():\n",
    "        if 'metrics' in result and not np.isnan(result['metrics']['MAPE (%)']):\n",
    "            if result['metrics']['MAPE (%)'] < best_mape:\n",
    "                best_mape = result['metrics']['MAPE (%)']\n",
    "                best_config = config_name\n",
    "    \n",
    "    if best_config is None:\n",
    "        print(f\"Нет успешных результатов для {ticker}\")\n",
    "        return\n",
    "    \n",
    "    successful_configs = []\n",
    "    for config_name, result in ticker_results.items():\n",
    "        if 'predictions' in result and len(result['predictions']) > 0:\n",
    "            successful_configs.append(config_name)\n",
    "    \n",
    "    if len(successful_configs) == 0:\n",
    "        print(f\"Нет данных для построения графиков для {ticker}\")\n",
    "        return\n",
    "    \n",
    "    n_configs = len(successful_configs)\n",
    "    fig, axes = plt.subplots(1, n_configs, figsize=(15, 5))\n",
    "    if n_configs == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    fig.suptitle(f'FEDOT AutoML Walk-forward прогнозы для {ticker}', fontsize=14)\n",
    "    \n",
    "    for i, config_name in enumerate(successful_configs):\n",
    "        ax = axes[i]\n",
    "        result = ticker_results[config_name]\n",
    "        \n",
    "        predictions = result['predictions']\n",
    "        actuals = result['actuals']\n",
    "        \n",
    "        time_points = range(len(actuals))\n",
    "        ax.plot(time_points, actuals, label='Реальные значения', color='blue', linewidth=2)\n",
    "        ax.plot(time_points, predictions, label='Прогноз AutoML', color='red', linestyle='--', linewidth=2)\n",
    "        \n",
    "        metrics = result['metrics']\n",
    "        title = f\"{config_name}\"\n",
    "        if config_name == best_config:\n",
    "            title += \" (Лучшая)\"\n",
    "        title += f\"\\nMAPE: {metrics['MAPE (%)']:.2f}%, DA: {metrics['DA (%)']:.1f}%\"\n",
    "        \n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xlabel('Шаг времени')\n",
    "        ax.set_ylabel('Значение цены')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if best_config and 'model_analysis' in ticker_results[best_config]:\n",
    "        print(f\"\\nМодели, найденные лучшей конфигурацией {best_config}:\")\n",
    "        model_analysis = ticker_results[best_config]['model_analysis']\n",
    "        for model_name, count in sorted(model_analysis.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {model_name}: {count} раз(а)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ВИЗУАЛИЗАЦИЯ ПРОГНОЗОВ FEDOT AUTOML\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for ticker in test_tickers:\n",
    "    if ticker in all_results:\n",
    "        plot_fedot_forecasts(ticker, all_results[ticker], prepared_data[ticker])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fedot)",
   "language": "python",
   "name": "fedot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
